---
layout: post
title: "Come sit with us at the FilBench!"
date: 2025-11-22
authors: [ljvm]
description:  
categories: blog
---

I have high hopes for Filipino NLP.

Three years ago, I didn't have any involvement in the Filipino NLP space.
It just so happened that I was the only Filipino in the [spaCy](https://spacy.io) team[^1], and despite that, there's no Tagalog language support in the library.
Perhaps it was nice to *represent*: it felt like I was alone in a grocery aisle and I spotted a cereal box on the floor. I'm already there, I'm quite capable, so why not pick it up?

Fortunately, I realized that I wasn't alone.
I still remember cold-emailing [Blaise](https://blaisecruz.com/) and sharing [initial results](https://ljvmiranda921.github.io/notebook/2023/02/04/tagalog-pipeline/) of an NER pipeline (which soon became a core component of [calamanCy](https://github.com/ljvmiranda921/calamanCy)).
Through him, I got connected with [Joseph](https://www.josephimperial.com/home), whose works I've been reading for quite a while.
I still remember us meeting in person back in 2023, and I guess the rest is history!

Fast-forward to 2025, across many life events and other collaborations, I also met Ely and Conner through cold emails.
We started with an annotation project that didn't really materialize, but we pivoted into a more impactful project on language model evaluation.
That project soon turned into FilBench, and together with Joseph and Blaise, it was published in EMNLP Main!

I know it's confusing to call both the evaluation benchmark and this *collective* as FilBench[^2], though it's quite apt.
Back in my undergrad, I remember the idea of "org benches" where people hang out to do work.
There was something special about having a designated bench, where people could gather, plan, and collaborate.
That's what I think FilBench represents: a bench for Filipino NLP researchers to call home.






[^1]: During the pre-LLM era, [spaCy](https://spacy.io/) was very useful and popular in building linguistic processing pipelines for tasks such as named-entity recognition, dependency parsing, and classification.  

[^2]: I actually renamed all instances of the benchmark into **FilBench-Eval** just to lessen the confusion.

